{"appId":"winget_app_MintplexLabs.AnythingLLM","appShortcutName":"Winget Application","appDisplayName":"AnythingLLM","authorId":"winget","releaseTagName":"winget-1.6.9","downloadUrls":{"1":{"installerType":"WindowsInstallerExe","asset":"","url":"https://s3.us-west-1.amazonaws.com/public.useanything.com/latest/AnythingLLMDesktop.exe"},"0":{"installerType":"WindowsInstallerMsi","asset":"","url":""}},"install":{"win32":{"assetId":1,"exec":null,"installerArgs":null},"winarm":null,"linux":null,"linuxArm64":null,"linuxArm7":null,"android":null},"displayImages":[],"description":"The all-in-one AI app you were looking for. Chat with your docs, use AI Agents, hyper-configurable, multi-user, & no frustrating set up required.\n\nAnythingLLM is a full-stack application that enables you to turn any document, resource, or piece of content into context that any LLM can use as references during chatting. This application allows you to pick and choose which LLM or Vector Database you want to use as well as supporting multi-user management and permissions.\nWhat's New:\n\nAMD GPU Support + More\n\nOur internal Ollama provider was bumped to the latest version (0.3.14) which includes support for AMD GPUs, as well as other improvements.\nFor Windows, we install the additional support files during the installation process automatically. For MacOS, there is nothing to do.\nImport any Ollama Model Tag or Hugging Face Model\n\nYou can now import any Ollama model tag or Hugging Face model into AnythingLLM using the default Ollama provider. Simply enter the tag or URL and hit import. This allows you to use models that are not explicitly listed in the UI.\nJust paste in the ollama run command and hit import!\nPulling from Ollama.com (opens in a new tab) example: ollama run mistral-nemo\nPulling from Hugging Face (opens in a new tab) example: ollama run hf.co/bartowski/Llama-3.2-1B-Instruct-GGUF\nComputer Use (Anthropic AI)\n\nAnythingLLM can now leverage the new Anthropic AI Computer Use models.\nThis is an experimental feature (opens in a new tab) and must be explicitly enabled in your system settings.\nFind-in-page support for workspace chat\n\nYou can now find specific text within the workspace chat window. Simply press Ctrl+F to open the finder input at the top-right of the chat window.\nOther Improvements:\n\n-\n  Added NovitaAI (opens in a new tab) as a supported LLM Provider\n-\n  Improved document metadata for embedding/RAG results\n-\n  Added Session Token support for AWS BedRock inference\n-\n  Added API docs update\n-\n  Added API Limit/orderBy for workspace/chats endpoint\n-\n  Added support for INO filetype\nBug Fixes:\n\n-\n  Patch restriction where localhost address web scraping was blocked.\n-\n  Patch bad reference for Ephemeral agent invocation\n-\n  Fixed issue where files with non-latin characters were not being respected when uploaded via API\nWhat's Next:\n\n- Community Hub for Agent skills, workspace sharing, and more. Pull Request #2555 (opens in a new tab)\n- True dark mode and light mode UI Pull Request #2481 (opens in a new tab)","repo":{"author":"microsoft","repo":"winget-pkgs"},"version":"1.6.9","site":"https://anythingllm.com/","source":"Mintplex Labs Inc","license_or_tos":"MIT","resources":null,"verified":false}