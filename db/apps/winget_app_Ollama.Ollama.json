{"appId":"winget_app_Ollama.Ollama","appShortcutName":"Winget Application","appDisplayName":"Ollama","authorId":"winget","releaseTagName":"winget-0.4.2","downloadUrls":{"0":{"installerType":"WindowsInstallerMsi","asset":"","url":""},"1":{"installerType":"WindowsInstallerExe","asset":"","url":"https://github.com/ollama/ollama/releases/download/v0.4.2/OllamaSetup.exe"}},"install":{"win32":{"assetId":1,"exec":null,"installerArgs":null},"winarm":null,"linux":null,"linuxArm64":null,"linuxArm7":null,"android":null},"displayImages":[],"description":"Get up and running with large language models locally.\n\n\nWhat's Changed\n- Make KV cache shifting more reliable\n- Fix NVIDIA JetPack support\n- Fix extraneous newlines when displaying template/system layers\n- Fix llama3.2-vision on multiple CUDA GPUs\n- Fix error when embeddings contains only whitespace\n- Report line numbers for parser errors in create\nNew Contributors\n- @arbusam made their first contribution in https://github.com/ollama/ollama/pull/7580\n- @neomantra made their first contribution in https://github.com/ollama/ollama/pull/7604\n- @frances720 made their first contribution in https://github.com/ollama/ollama/pull/7517\n- @ivostoykov made their first contribution in https://github.com/ollama/ollama/pull/5827\n- @prasad89 made their first contribution in https://github.com/ollama/ollama/pull/7521\n- @joey5403 made their first contribution in https://github.com/ollama/ollama/pull/7418\nFull Changelog: https://github.com/ollama/ollama/compare/v0.4.1...v0.4.2-rc0","repo":{"author":"microsoft","repo":"winget-pkgs"},"version":"0.4.2","site":"https://ollama.com/","source":"Ollama","license_or_tos":"MIT","resources":null,"verified":false}