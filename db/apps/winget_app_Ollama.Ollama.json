{"appId":"winget_app_Ollama.Ollama","appShortcutName":"Winget Application","appDisplayName":"Ollama","authorId":"winget","releaseTagName":"winget-0.4.5","downloadUrls":{"1":{"installerType":"WindowsInstallerExe","asset":"","url":"https://github.com/ollama/ollama/releases/download/v0.4.5/OllamaSetup.exe"},"0":{"installerType":"WindowsInstallerMsi","asset":"","url":""}},"install":{"win32":{"assetId":1,"exec":null,"installerArgs":null},"winarm":null,"linux":null,"linuxArm64":null,"linuxArm7":null,"android":null},"displayImages":[],"description":"Get up and running with large language models locally.\n\n\nWhat's Changed\n- Fixed issue where HTTPS_PROXY and HTTP_PROXY environment variables would have no effect\n- Ollama will now accept X-Stainless-Retry-Count used by many OpenAI API clients\n- Fix issue where importing certain GGUF files would result in the incorrect quantization level\n- ollama push will now print the uploaded model URL on ollama.com\nNew Contributors\n- @rrg92 made their first contribution in https://github.com/ollama/ollama/pull/7438\n- @oza6ut0ne made their first contribution in https://github.com/ollama/ollama/pull/6910\n- @josStorer made their first contribution in https://github.com/ollama/ollama/pull/4118\n- @patcher9 made their first contribution in https://github.com/ollama/ollama/pull/7811\n- @erikos made their first contribution in https://github.com/ollama/ollama/pull/3591\n- @sunnybak made their first contribution in https://github.com/ollama/ollama/pull/7831\nFull Changelog: https://github.com/ollama/ollama/compare/v0.4.4...v0.4.5","repo":{"author":"microsoft","repo":"winget-pkgs"},"version":"0.4.5","site":"https://ollama.com/","source":"Ollama","license_or_tos":"MIT","resources":null,"verified":false}