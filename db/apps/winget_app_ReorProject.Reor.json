{"appId":"winget_app_ReorProject.Reor","appShortcutName":"Winget Application","appDisplayName":"Reor","authorId":"winget","releaseTagName":"winget-0.2.31","downloadUrls":{"0":{"installerType":"WindowsInstallerMsi","asset":"","url":""},"1":{"installerType":"WindowsInstallerExe","asset":"","url":"https://github.com/reorproject/reor/releases/download/v0.2.31/Reor_0.2.31.exe"}},"install":{"win32":{"assetId":1,"exec":null,"installerArgs":null},"winarm":null,"linux":null,"linuxArm64":null,"linuxArm7":null,"android":null},"displayImages":[],"description":"Private & local AI personal knowledge management app.\n\nReor is an AI-powered desktop note-taking app: it automatically links related notes, answers questions on your notes, provides semantic search and can generate AI flashcards. Everything is stored locally and you can edit your notes with an Obsidian-like markdown editor.\nThe hypothesis of the project is that AI tools for thought should run models locally by default. Reor stands on the shoulders of the giants Ollama, Transformers.js & LanceDB to enable both LLMs and embedding models to run locally:\n1. Every note you write is chunked and embedded into an internal vector database.\n2. Related notes are connected automatically via vector similarity.\n3. LLM-powered Q&A does RAG on your corpus of notes.\n4. Everything can be searched semantically.\nOne way to think about Reor is as a RAG app with two generators: the LLM and the human. In Q&A mode, the LLM is fed retrieved context from the corpus to help answer a query. Similarly, in editor mode, the human can toggle the sidebar to reveal related notes \"retrieved\" from the corpus. This is quite a powerful way of \"augmenting\" your thoughts by cross-referencing ideas in a current note against related ideas from your corpus.\n","repo":{"author":"microsoft","repo":"winget-pkgs"},"version":"0.2.31","site":"https://www.reorproject.org/","source":"Sam L'Huillier","license_or_tos":"AGPL-3.0","resources":null,"verified":false}