{"appId":"winget_app_Mozilla.llamafile","appShortcutName":"Winget Application","appDisplayName":"llamafile","authorId":"winget","releaseTagName":"winget-0.8.15","downloadUrls":{"0":{"installerType":"WindowsInstallerMsi","asset":"","url":""},"1":{"installerType":"WindowsInstallerExe","asset":"","url":"https://github.com/Mozilla-Ocho/llamafile/releases/download/0.8.15/llamafile-0.8.15"}},"install":{"win32":{"assetId":1,"exec":null,"installerArgs":null},"winarm":null,"linux":null,"linuxArm64":null,"linuxArm7":null,"android":null},"displayImages":[],"description":"Distribute and run LLMs with a single file.\n\nllamafile lets you distribute and run LLMs with a single file.\nOur goal is to make open LLMs much more accessible to both developers and end users. We're doing that by combining llama.cpp with Cosmopolitan Libc into one framework that collapses all the complexity of LLMs down to a single-file executable (called a \"llamafile\") that runs locally on most computers, with no installation.\n","repo":{"author":"microsoft","repo":"winget-pkgs"},"version":"0.8.15","site":"https://github.com/Mozilla-Ocho","source":"WinGet","license_or_tos":"Apache-2.0","resources":null,"verified":false}